df_test <- df %>% tail(20) %>%
select(x1,x2)
df_test
predict(df_test, newdata = fit_1)
df_test
predict(df_test, newdata = fit_1)
{
plot(df_train$x2, x2_res,
ylab = "Residuals",
xlab = "x2",
main = "x2 Residuals")
abline(0,0)
}
predict(df_test, newdata = fit_1)
predict(data.frame(df_test), newdata = fit_1)
df_test
df_test
predict(df_test, newdata = fit_1)
predict(data.fram(df_test), newdata = fit_1)
predict(data.frame(df_test), newdata = fit_1)
predict(fit_1, newdata = df_test)
predictions_fit_1 <- predict(fit_1, newdata = df_test)
summary(fit_1)
{
plot(df_train$x1, x1_res,
ylab = "Residuals",
xlab = "x1",
main = "x1 Residuals")
abline(0,0)
}
var1 <- rnorm(1000,0,1)
var2 <- rnorm(1000,0,1)
fit_3 <- lm(var1 ~ var2)
summary(fit_3)
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
var1 <- rnorm(1000,0,1)
var2 <- rnorm(1000,0,1)
fit_3 <- lm(var1 ~ var2)
summary(fit_3)
z.scores <- rep (NA, 100)
for (k in 1:100) {
var1 <- rnorm (1000,0,1)
var2 <- rnorm (1000,0,1)
fit <- lm (var2 ~ var1)
z.scores[k] <- coef(fit)[2]/se.coef(fit)[2]
}
?se.coef
??se.coef
var1 <- rnorm(1000,0,1)
var2 <- rnorm(1000,0,1)
fit_3 <- lm(var1 ~ var2)
summary(fit_3)
z.scores <- rep (NA, 100)
for (k in 1:100) {
var1 <- rnorm (1000,0,1)
var2 <- rnorm (1000,0,1)
fit <- lm (var2 ~ var1)
z.scores[k] <- coef(fit)[2] / se.coef(fit)[2]
}
se.coef(fit)
se.coef(fit_3)
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
display(fit_1)
summary(fit_1)
df <- read.table("http://www.stat.columbia.edu/~gelman/arm/examples/pyth/exercise2.1.dat", header = TRUE)
# using head to get the first 40 observations
df_train <- df %>% head(40)
# using tail to get the last 20 observations
df_test <- df %>% tail(20) %>%
select(x1,x2)
fit_1 <- lm(y ~ x1 + x2, data = df_train)
# the intercept is equal to 1.31, the x1 coefficient is equal to .514, the x2
# coefficient is equal to .806. In context this means that the average value of
# y when x1 and x2 are both 0 is 1.31. For every 1 unit increase in x1, y
# increases by .514 on average, holding x2 constant. For every 1 unit increase
# in x2, y increased by .806 on average, holding x1 constant. The R squared value is about .97, meaning that the model accounts for about 97% of variation.
y_vs_x1 <- ggplot(df_train, aes(x = x1, y = y)) +
geom_point() +
geom_smooth(method = "lm", se = FALSE) +
labs(title = "Y vs x1") +
theme_classic()
y_vs_x2 <- ggplot(df_train, aes(x = x2, y = y)) +
geom_point() +
geom_smooth(method = "lm", se = FALSE) +
theme_classic()
# doing residual plots. These plots show the actual values of x1 plotted against
# the residual of x1 in the above model. The horizontal line is at 0, meaning
# that the observed x1 and the predicted x1 were the same.
x1_fit <- lm(y ~ x1, data = df_train)
x1_res <- resid(x1_fit)
x2_fit <- lm(y ~ x2, data = df_train)
x2_res <- resid(x2_fit)
{
plot(df_train$x1, x1_res,
ylab = "Residuals",
xlab = "x1",
main = "x1 Residuals")
abline(0,0)
}
{
plot(df_train$x2, x2_res,
ylab = "Residuals",
xlab = "x2",
main = "x2 Residuals")
abline(0,0)
}
# making predictions for the test data
predictions_fit_1 <- predict(fit_1, newdata = df_test)
summary(fit_1)
y_vs_x1 <- ggplot(df_train, aes(x = x1, y = y)) +
geom_point() +
geom_smooth(method = "lm", se = FALSE) +
labs(title = "Y vs x1") +
theme_classic()
y_vs_x2 <- ggplot(df_train, aes(x = x2, y = y)) +
geom_point() +
geom_smooth(method = "lm", se = FALSE) +
theme_classic()
ggplot(df_train, aes(x = x1, y = y)) +
geom_point() +
geom_smooth(method = "lm", se = FALSE) +
labs(title = "Y vs x1") +
theme_classic()
ggplot(df_train, aes(x = x2, y = y)) +
geom_point() +
geom_smooth(method = "lm", se = FALSE) +
theme_classic()
ggplot(df_train, aes(x = x1, y = y)) +
geom_point() +
geom_smooth(method = "lm", se = FALSE) +
labs(title = "Y vs x1") +
theme_classic()
ggplot(df_train, aes(x = x2, y = y)) +
geom_point() +
geom_smooth(method = "lm", se = FALSE) +
labs(title = "Y vs  x2") +
theme_classic()
# doing residual plots. These plots show the actual values of x1 plotted against
# the residual of x1 in the above model. The horizontal line is at 0, meaning
# that the observed x1 and the predicted x1 were the same.
x1_fit <- lm(y ~ x1, data = df_train)
x1_res <- resid(x1_fit)
x2_fit <- lm(y ~ x2, data = df_train)
x2_res <- resid(x2_fit)
{
plot(df_train$x1, x1_res,
ylab = "Residuals",
xlab = "x1",
main = "x1 Residuals")
abline(0,0)
}
{
plot(df_train$x2, x2_res,
ylab = "Residuals",
xlab = "x2",
main = "x2 Residuals")
abline(0,0)
}
# the intercept is equal to 1.31, the x1 coefficient is equal to .514, the x2
# coefficient is equal to .806. In context this means that the average value of
# y when x1 and x2 are both 0 is 1.31. For every 1 unit increase in x1, y
# increases by .514 on average, holding x2 constant. For every 1 unit increase
# in x2, y increased by .806 on average, holding x1 constant. The R squared
# value is about .97, meaning that the model accounts for about 97% of
# variation.
summary(fit_1)
# plots of y vs x1 and x2
ggplot(df_train, aes(x = x1, y = y)) +
geom_point() +
geom_smooth(method = "lm", se = FALSE) +
labs(title = "Y vs x1") +
theme_classic()
ggplot(df_train, aes(x = x2, y = y)) +
geom_point() +
geom_smooth(method = "lm", se = FALSE) +
labs(title = "Y vs  x2") +
theme_classic()
# making predictions for the test data
predictions_fit_1 <- predict(fit_1, newdata = df_test)
predictions_fit_1
# making predictions for the test data
predict(fit_1, newdata = df_test)
install.packages("arm")
knitr::opts_chunk$set(echo = TRUE)
library(arm)
library(tidyverse)
# the intercept is equal to 1.31, the x1 coefficient is equal to .514, the x2
# coefficient is equal to .806. In context this means that the average value of
# y when x1 and x2 are both 0 is 1.31. For every 1 unit increase in x1, y
# increases by .514 on average, holding x2 constant. For every 1 unit increase
# in x2, y increased by .806 on average, holding x1 constant. The R squared
# value is about .97, meaning that the model accounts for about 97% of
# variation.
display(fit_1)
var1 <- rnorm(1000,0,1)
var2 <- rnorm(1000,0,1)
fit_3 <- lm(var1 ~ var2)
summary(fit_3)
z.scores <- rep (NA, 100)
for (k in 1:100) {
var1 <- rnorm (1000,0,1)
var2 <- rnorm (1000,0,1)
fit <- lm (var2 ~ var1)
#z.scores[k] <- coef(fit)[2] / se.coef(fit)[2]
}
z.scores
for (k in 1:100) {
var1 <- rnorm (1000,0,1)
var2 <- rnorm (1000,0,1)
fit <- lm (var2 ~ var1)
z.scores[k] <- coef(fit)[2] / se.coef(fit)[2]
}
z.scores
sum(z.scores >= 2)
var1 <- rnorm(1000,0,1)
var2 <- rnorm(1000,0,1)
fit_3 <- lm(var1 ~ var2)
# the coefficients are not statistically significant
summary(fit_3)
z.scores <- rep (NA, 100)
for (k in 1:100) {
var1 <- rnorm (1000,0,1)
var2 <- rnorm (1000,0,1)
fit <- lm (var2 ~ var1)
z.scores[k] <- coef(fit)[2] / se.coef(fit)[2]
}
sum(z.scores >= 2)
sum(z.scores >= 2)
?predict
# making predictions for the test data
predict(fit_1, newdata = df_test, interview = "prediction")
predict(fit_1, newdata = df_test, interview = "prediction")
# making predictions for the test data
predict(fit_1, newdata = df_test, interval =  = "prediction")
# making predictions for the test data
predict(fit_1, newdata = df_test, interval = "prediction")
# this code pretty much all came from the book
var1 <- rnorm(1000,0,1)
var2 <- rnorm(1000,0,1)
fit_3 <- lm(var1 ~ var2)
# the coefficients are not statistically significant
summary(fit_3)
z.scores <- rep (NA, 100)
for (k in 1:100) {
var1 <- rnorm (1000,0,1)
var2 <- rnorm (1000,0,1)
fit <- lm (var2 ~ var1)
z.scores[k] <- coef(fit)[2] / se.coef(fit)[2]
}
# counting the amount of values that are statistically significant
sum <- sum(z.scores >= 2)
sum
install.packages("descr")
knitr::opts_chunk$set(echo = TRUE)
library(arm)
library(tidyverse)
# plots of y vs x1 and x2
ggplot(df_train, aes(x = x1, y = y)) +
geom_point() +
geom_smooth(method = "lm", se = FALSE) +
labs(title = "Y vs x1") +
theme_classic()
knitr::opts_chunk$set(echo = TRUE)
library(arm)
library(tidyverse)
df <- read.table("http://www.stat.columbia.edu/~gelman/arm/examples/pyth/exercise2.1.dat",
header = TRUE)
# using head to get the first 40 observations
df_train <- df %>% head(40)
# using tail to get the last 20 observations
df_test <- df %>% tail(20) %>%
select(x1,x2)
fit_1 <- lm(y ~ x1 + x2, data = df_train)
# the intercept is equal to 1.31, the x1 coefficient is equal to .514, the x2
# coefficient is equal to .806. In context this means that the average value of
# y when x1 and x2 are both 0 is 1.31. For every 1 unit increase in x1, y
# increases by .514 on average, holding x2 constant. For every 1 unit increase
# in x2, y increased by .806 on average, holding x1 constant. The R squared
# value is about .97, meaning that the model accounts for about 97% of
# variation.
display(fit_1)
# plots of y vs x1 and x2
ggplot(df_train, aes(x = x1, y = y)) +
geom_point() +
geom_smooth(method = "lm", se = FALSE) +
labs(title = "Y vs x1") +
theme_classic()
ggplot(df_train, aes(x = x2, y = y)) +
geom_point() +
geom_smooth(method = "lm", se = FALSE) +
labs(title = "Y vs  x2") +
theme_classic()
df_test
predictions
predictions <- predict(fit_1, newdata = df_test, interval = "prediction")
predictions
predictions <- predict(fit_1, newdata = df_test)
predictions
?cbind
df_test
new_df <- predictions %>%
cbind(df_test)
new_df
new_df <- cbind(predictions, df_test)
new_df
ggplot(df_train, aes(x = x1, y = y)) +
geom_point() +
geom_point(data = new_df, aes(x = x1, y = predictions, col = "red")) +
geom_smooth(method = "lm", se = FALSE) +
labs(title = "Y vs x1") +
theme_classic()
ggplot(df_train, aes(x = x2, y = y)) +
geom_point() +
geom_point(data = new_df, aes(x = x2, y = predictions, col = "red")) +
geom_smooth(method = "lm", se = FALSE) +
labs(title = "Y vs  x2") +
theme_classic()
ggplot(df_train, aes(x = x1, y = y)) +
geom_point() +
geom_point(data = new_df, aes(x = x1, y = predictions, col = "red")) +
geom_smooth(method = "lm", se = FALSE) +
labs(title = "Y vs x1 (Predictions)") +
theme_classic()
ggplot(df_train, aes(x = x2, y = y)) +
geom_point() +
geom_point(data = new_df, aes(x = x2, y = predictions, col = "red")) +
geom_smooth(method = "lm", se = FALSE) +
labs(title = "Y vs  x2 (Predictions)") +
theme_classic()
ggplot(df_train, aes(x = x1, y = y)) +
geom_point() +
geom_point(data = new_df, aes(x = x1, y = predictions), col = "red") +
geom_smooth(method = "lm", se = FALSE) +
labs(title = "Y vs x1 (Predictions)") +
theme_classic()
ggplot(df_train, aes(x = x2, y = y)) +
geom_point() +
geom_point(data = new_df, aes(x = x2, y = predictions), col = "red") +
geom_smooth(method = "lm", se = FALSE) +
labs(title = "Y vs  x2 (Predictions)") +
theme_classic()
# doing residual plots. These plots show the actual values of x1 plotted against
# the residual of x1 in the above model. The horizontal line is at 0, meaning
# that the observed x1 and the predicted x1 were the same.
x1_fit <- lm(y ~ x1, data = df_train)
x1_res <- resid(x1_fit)
x2_fit <- lm(y ~ x2, data = df_train)
x2_res <- resid(x2_fit)
{
plot(df_train$x1, x1_res,
ylab = "Residuals",
xlab = "x1",
main = "x1 Residuals")
abline(0,0)
}
{
plot(df_train$x2, x2_res,
ylab = "Residuals",
xlab = "x2",
main = "x2 Residuals")
abline(0,0)
}
# this code pretty much all came from the book
var1 <- rnorm(1000,0,1)
var2 <- rnorm(1000,0,1)
fit_3 <- lm(var1 ~ var2)
# the coefficients are not statistically significant
summary(fit_3)
knitr::opts_chunk$set(echo = TRUE)
library(arm)
library(tidyverse)
set.seed(123)
df <- read.table("http://www.stat.columbia.edu/~gelman/arm/examples/pyth/exercise2.1.dat",
header = TRUE)
# using head to get the first 40 observations
df_train <- df %>% head(40)
# using tail to get the last 20 observations
df_test <- df %>% tail(20) %>%
select(x1,x2)
fit_1 <- lm(y ~ x1 + x2, data = df_train)
# the intercept is equal to 1.31, the x1 coefficient is equal to .514, the x2
# coefficient is equal to .806. In context this means that the average value of
# y when x1 and x2 are both 0 is 1.31. For every 1 unit increase in x1, y
# increases by .514 on average, holding x2 constant. For every 1 unit increase
# in x2, y increased by .806 on average, holding x1 constant. The R squared
# value is about .97, meaning that the model accounts for about 97% of
# variation.
display(fit_1)
# plots of y vs x1 and x2
ggplot(df_train, aes(x = x1, y = y)) +
geom_point() +
geom_smooth(method = "lm", se = FALSE) +
labs(title = "Y vs x1") +
theme_classic()
ggplot(df_train, aes(x = x2, y = y)) +
geom_point() +
geom_smooth(method = "lm", se = FALSE) +
labs(title = "Y vs  x2") +
theme_classic()
# doing residual plots. These plots show the actual values of x1 plotted against
# the residual of x1 in the above model. The horizontal line is at 0, meaning
# that the observed x1 and the predicted x1 were the same.
x1_fit <- lm(y ~ x1, data = df_train)
x1_res <- resid(x1_fit)
x2_fit <- lm(y ~ x2, data = df_train)
x2_res <- resid(x2_fit)
{
plot(df_train$x1, x1_res,
ylab = "Residuals",
xlab = "x1",
main = "x1 Residuals")
abline(0,0)
}
{
plot(df_train$x2, x2_res,
ylab = "Residuals",
xlab = "x2",
main = "x2 Residuals")
abline(0,0)
}
# making predictions for the test data
predictions <- predict(fit_1, newdata = df_test)
new_df <- cbind(predictions, df_test)
ggplot(df_train, aes(x = x1, y = y)) +
geom_point() +
geom_point(data = new_df, aes(x = x1, y = predictions), col = "red") +
geom_smooth(method = "lm", se = FALSE) +
labs(title = "Y vs x1 (Predictions)") +
theme_classic()
ggplot(df_train, aes(x = x2, y = y)) +
geom_point() +
geom_point(data = new_df, aes(x = x2, y = predictions), col = "red") +
geom_smooth(method = "lm", se = FALSE) +
labs(title = "Y vs  x2 (Predictions)") +
theme_classic()
# this code pretty much all came from the book
var1 <- rnorm(1000,0,1)
var2 <- rnorm(1000,0,1)
fit_3 <- lm(var1 ~ var2)
# the coefficients are not statistically significant
summary(fit_3)
z.scores <- rep (NA, 100)
for (k in 1:100) {
var1 <- rnorm (1000,0,1)
var2 <- rnorm (1000,0,1)
fit <- lm (var2 ~ var1)
z.scores[k] <- coef(fit)[2] / se.coef(fit)[2]
}
# counting the amount of values that are statistically significant
sum_z <- sum(z.scores >= 2)
sum_z
knitr::opts_chunk$set(echo = TRUE)
library(arm)
library(tidyverse)
set.seed(124)
# this code pretty much all came from the book
var1 <- rnorm(1000,0,1)
var2 <- rnorm(1000,0,1)
fit_3 <- lm(var1 ~ var2)
# the coefficients are not statistically significant
summary(fit_3)
knitr::opts_chunk$set(echo = TRUE)
library(arm)
library(tidyverse)
set.seed(126)
# this code pretty much all came from the book
var1 <- rnorm(1000,0,1)
var2 <- rnorm(1000,0,1)
fit_3 <- lm(var1 ~ var2)
# the coefficients are not statistically significant
summary(fit_3)
z.scores <- rep (NA, 100)
for (k in 1:100) {
var1 <- rnorm (1000,0,1)
var2 <- rnorm (1000,0,1)
fit <- lm (var2 ~ var1)
z.scores[k] <- coef(fit)[2] / se.coef(fit)[2]
}
# counting the amount of values that are statistically significant
sum_z <- sum(z.scores >= 2)
sum_z
z.scores <- rep (NA, 100)
for (k in 1:100) {
var1 <- rnorm (1000,0,1)
var2 <- rnorm (1000,0,1)
fit <- lm (var2 ~ var1)
z.scores[k] <- coef(fit)[2] / se.coef(fit)[2]
}
# counting the amount of values that are statistically significant
sum_z <- sum(z.scores > 2)
z.scores <- rep (NA, 100)
for (k in 1:100) {
var1 <- rnorm (1000,0,1)
var2 <- rnorm (1000,0,1)
fit <- lm (var2 ~ var1)
z.scores[k] <- coef(fit)[2] / se.coef(fit)[2]
}
# counting the amount of values that are statistically significant
sum_z <- sum(z.scores > 2 | z.scores < -2)
sum_z
z.scores <- rep (NA, 100)
for (k in 1:100) {
var1 <- rnorm (1000,0,1)
var2 <- rnorm (1000,0,1)
fit <- lm (var2 ~ var1)
z.scores[k] <- coef(fit)[2] / se.coef(fit)[2]
}
# counting the amount of values that are statistically significant
sum_z <- sum(z.scores > 2 | z.scores < -2)
sum_z
